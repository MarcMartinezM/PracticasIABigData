{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df17e5c6-339e-4be2-8da6-efb80b75ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalar tensorflow con pip install tensorflow desde terminar anaconda prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb056ce-3a9b-472b-92a5-028b682ba0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import lliberias\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "# ver verson tensorFlow\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75064fad-5d66-4d4a-8b77-675d04e8d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descargamos \n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda1ae2-ed9a-49e4-acb2-fb8fe24e029c",
   "metadata": {},
   "source": [
    "## Analisis de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa708013-1360-4acc-99c5-1105a57c44ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# revisien la forma y tipo de los datos\n",
    "print(x_train.shape)# 60000 imagenes o numeros de 28x28 cada una\n",
    "print(x_train.dtype)# entero sin signos 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55bbf382-e632-47b5-b492-ec785b4d365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   8  76 202 254 255 163  37   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  13 182 253 253 253 253 253 253  23\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  15 179 253 253 212  91 218 253 253 179\n",
      "  109   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 105 253 253 160  35 156 253 253 253 253\n",
      "  250 113   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  19 212 253 253  88 121 253 233 128  91 245\n",
      "  253 248 114   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 104 253 253 110   2 142 253  90   0   0  26\n",
      "  199 253 248  63   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1 173 253 253  29   0  84 228  39   0   0   0\n",
      "   72 251 253 215  29   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  36 253 253 203  13   0   0   0   0   0   0   0\n",
      "    0  82 253 253 170   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  36 253 253 164   0   0   0   0   0   0   0   0\n",
      "    0  11 198 253 184   6   0   0   0   0]\n",
      " [  0   0   0   0   0   0  36 253 253  82   0   0   0   0   0   0   0   0\n",
      "    0   0 138 253 253  35   0   0   0   0]\n",
      " [  0   0   0   0   0   0 128 253 253  47   0   0   0   0   0   0   0   0\n",
      "    0   0  48 253 253  35   0   0   0   0]\n",
      " [  0   0   0   0   0   0 154 253 253  47   0   0   0   0   0   0   0   0\n",
      "    0   0  48 253 253  35   0   0   0   0]\n",
      " [  0   0   0   0   0   0 102 253 253  99   0   0   0   0   0   0   0   0\n",
      "    0   0  48 253 253  35   0   0   0   0]\n",
      " [  0   0   0   0   0   0  36 253 253 164   0   0   0   0   0   0   0   0\n",
      "    0  16 208 253 211  17   0   0   0   0]\n",
      " [  0   0   0   0   0   0  32 244 253 175   4   0   0   0   0   0   0   0\n",
      "    0  44 253 253 156   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 171 253 253  29   0   0   0   0   0   0   0\n",
      "   30 217 253 188  19   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 171 253 253  59   0   0   0   0   0   0  60\n",
      "  217 253 253  70   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  78 253 253 231  48   0   0   0  26 128 249\n",
      "  253 244  94  15   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   8 151 253 253 234 101 121 219 229 253 253\n",
      "  201  80   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  38 232 253 253 253 253 253 253 253 201\n",
      "   66   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# mostrem les dades d'una imatge\n",
    "print(x_train[88])\n",
    "\n",
    "#ostramos la salida\n",
    "print(y_train[69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d4b0e0e-5b72-423f-a760-816eb62fc9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21394260b80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ver la imagen \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[88],cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41534d-1a8a-4921-bf48-94b35e3586a6",
   "metadata": {},
   "source": [
    "## Pre-processament de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b38351-1ae1-4321-b388-1e99c7780bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.03137255 0.29803923\n",
      "  0.7921569  0.99607843 1.         0.6392157  0.14509805 0.00784314\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05098039 0.7137255  0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.09019608\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05882353 0.7019608  0.99215686 0.99215686\n",
      "  0.83137256 0.35686275 0.85490197 0.99215686 0.99215686 0.7019608\n",
      "  0.42745098 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4117647  0.99215686 0.99215686 0.627451\n",
      "  0.13725491 0.6117647  0.99215686 0.99215686 0.99215686 0.99215686\n",
      "  0.98039216 0.44313726 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07450981 0.83137256 0.99215686 0.99215686 0.34509805\n",
      "  0.4745098  0.99215686 0.9137255  0.5019608  0.35686275 0.9607843\n",
      "  0.99215686 0.972549   0.44705883 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.40784314 0.99215686 0.99215686 0.43137255 0.00784314\n",
      "  0.5568628  0.99215686 0.3529412  0.         0.         0.10196079\n",
      "  0.78039217 0.99215686 0.972549   0.24705882 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.00392157 0.6784314  0.99215686 0.99215686 0.11372549 0.\n",
      "  0.32941177 0.89411765 0.15294118 0.         0.         0.\n",
      "  0.28235295 0.9843137  0.99215686 0.84313726 0.11372549 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.14117648 0.99215686 0.99215686 0.79607844 0.05098039 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.32156864 0.99215686 0.99215686 0.6666667  0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.14117648 0.99215686 0.99215686 0.6431373  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04313726 0.7764706  0.99215686 0.72156864 0.02352941\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.14117648 0.99215686 0.99215686 0.32156864 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5411765  0.99215686 0.99215686 0.13725491\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.5019608  0.99215686 0.99215686 0.18431373 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1882353  0.99215686 0.99215686 0.13725491\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.6039216  0.99215686 0.99215686 0.18431373 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1882353  0.99215686 0.99215686 0.13725491\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.4        0.99215686 0.99215686 0.3882353  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1882353  0.99215686 0.99215686 0.13725491\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.14117648 0.99215686 0.99215686 0.6431373  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0627451  0.8156863  0.99215686 0.827451   0.06666667\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.1254902  0.95686275 0.99215686 0.6862745  0.01568628 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17254902 0.99215686 0.99215686 0.6117647  0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.67058825 0.99215686 0.99215686 0.11372549 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11764706 0.8509804  0.99215686 0.7372549  0.07450981 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.67058825 0.99215686 0.99215686 0.23137255 0.\n",
      "  0.         0.         0.         0.         0.         0.23529412\n",
      "  0.8509804  0.99215686 0.99215686 0.27450982 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.30588236 0.99215686 0.99215686 0.90588236 0.1882353\n",
      "  0.         0.         0.         0.10196079 0.5019608  0.9764706\n",
      "  0.99215686 0.95686275 0.36862746 0.05882353 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03137255 0.5921569  0.99215686 0.99215686 0.91764706\n",
      "  0.39607844 0.4745098  0.85882354 0.8980392  0.99215686 0.99215686\n",
      "  0.7882353  0.3137255  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14901961 0.9098039  0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.7882353\n",
      "  0.25882354 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# convertir el tipo unit8 a float32 per tener representacio amb decimals\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "x_train.dtype\n",
    "\n",
    "#normalitzacion\n",
    "x_train = x_train / 255\n",
    "x_test  = x_test / 255\n",
    "\n",
    "\n",
    "#observem el resultat\n",
    "\n",
    "print(x_train[88])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7999be5e-8685-4d2b-bf46-370cf1aff539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Convertimos la matriz 28x28 eb un vector unidimensional de 784\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "# comprovemmos resultado\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9da3f04-5035-4b34-8426-014ab9c07f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#transoformamos la slaida a un vector boolean mida 10\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)\n",
    "\n",
    "#comprobamos el reusltado\n",
    "\n",
    "print(y_train[88])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe062d3-a6c3-4c3f-a705-ff03460a6eb0",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28aa939f-24dd-4d44-bc86-31e0e51d5fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,960\n",
      "Trainable params: 7,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# librerias necesarias\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# defir el tipis de xarxa neuronal\n",
    "model = Sequential()\n",
    "\n",
    "# afegim una capa de 10 neuronas amb 784 antradas y funcion d'activacio sigmoid\n",
    "model.add(Dense(10, activation = 'sigmoid', input_shape=(784,)))\n",
    "\n",
    "# afegim una capa de sortida de 10 neuronas amb funcions d'activacio softmax\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "#visualitzem l'estructura de la xarxa neuronal\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7fd161-3bd0-4629-9d1d-eb5b8e5eba00",
   "metadata": {},
   "source": [
    "## proces d'entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2925e854-e707-47a7-9c87-f034fea0270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2675 - accuracy: 0.9255\n",
      "Epoch 2/55\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2663 - accuracy: 0.9259\n",
      "Epoch 3/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2652 - accuracy: 0.9263\n",
      "Epoch 4/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2642 - accuracy: 0.9264\n",
      "Epoch 5/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2632 - accuracy: 0.9266\n",
      "Epoch 6/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2621 - accuracy: 0.9271\n",
      "Epoch 7/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2612 - accuracy: 0.9272\n",
      "Epoch 8/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2602 - accuracy: 0.9276\n",
      "Epoch 9/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2592 - accuracy: 0.9279\n",
      "Epoch 10/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2583 - accuracy: 0.9280\n",
      "Epoch 11/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2574 - accuracy: 0.9280\n",
      "Epoch 12/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2564 - accuracy: 0.9284\n",
      "Epoch 13/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2556 - accuracy: 0.9287\n",
      "Epoch 14/55\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2548 - accuracy: 0.9289\n",
      "Epoch 15/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2539 - accuracy: 0.9288\n",
      "Epoch 16/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2531 - accuracy: 0.9293\n",
      "Epoch 17/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2523 - accuracy: 0.9294\n",
      "Epoch 18/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2516 - accuracy: 0.9299\n",
      "Epoch 19/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2508 - accuracy: 0.9297\n",
      "Epoch 20/55\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2500 - accuracy: 0.9302\n",
      "Epoch 21/55\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2493 - accuracy: 0.9303\n",
      "Epoch 22/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2484 - accuracy: 0.9306\n",
      "Epoch 23/55\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2477 - accuracy: 0.9305\n",
      "Epoch 24/55\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2471 - accuracy: 0.9302\n",
      "Epoch 25/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2464 - accuracy: 0.9307\n",
      "Epoch 26/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2457 - accuracy: 0.9313\n",
      "Epoch 27/55\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2449 - accuracy: 0.9312\n",
      "Epoch 28/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2443 - accuracy: 0.9316\n",
      "Epoch 29/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2437 - accuracy: 0.9316\n",
      "Epoch 30/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2430 - accuracy: 0.9320\n",
      "Epoch 31/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2424 - accuracy: 0.9319\n",
      "Epoch 32/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2418 - accuracy: 0.9324\n",
      "Epoch 33/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2411 - accuracy: 0.9324\n",
      "Epoch 34/55\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2406 - accuracy: 0.9324\n",
      "Epoch 35/55\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2400 - accuracy: 0.9328\n",
      "Epoch 36/55\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2393 - accuracy: 0.9330\n",
      "Epoch 37/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2387 - accuracy: 0.9336\n",
      "Epoch 38/55\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2382 - accuracy: 0.9328\n",
      "Epoch 39/55\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2377 - accuracy: 0.9336\n",
      "Epoch 40/55\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2371 - accuracy: 0.9335\n",
      "Epoch 41/55\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2366 - accuracy: 0.9336\n",
      "Epoch 42/55\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2360 - accuracy: 0.9336\n",
      "Epoch 43/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2356 - accuracy: 0.9337\n",
      "Epoch 44/55\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2350 - accuracy: 0.9340\n",
      "Epoch 45/55\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2345 - accuracy: 0.9343\n",
      "Epoch 46/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2340 - accuracy: 0.9342\n",
      "Epoch 47/55\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2335 - accuracy: 0.9343\n",
      "Epoch 48/55\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2329 - accuracy: 0.9344\n",
      "Epoch 49/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2324 - accuracy: 0.9344\n",
      "Epoch 50/55\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2320 - accuracy: 0.9350\n",
      "Epoch 51/55\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2315 - accuracy: 0.9348\n",
      "Epoch 52/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2310 - accuracy: 0.9350\n",
      "Epoch 53/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2306 - accuracy: 0.9352\n",
      "Epoch 54/55\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2302 - accuracy: 0.9352\n",
      "Epoch 55/55\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2296 - accuracy: 0.9353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x213922526d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configuracio del proces d'entrenament\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])\n",
    "\n",
    "#inici de l'entrenament\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d195e3e8-3aa1-44da-858e-cd962f834cb8",
   "metadata": {},
   "source": [
    "## evaluacio del model obtingut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01db0e81-faab-4c3c-89ef-8409d17a1e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2692 - accuracy: 0.9231\n",
      "test lost 0.26916614174842834\n",
      "test accuracy 0.9230999946594238\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('test lost', test_loss)\n",
    "print('test accuracy', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dee38f-246d-4bd0-88a0-b0a75fa1ec26",
   "metadata": {},
   "source": [
    "### generacio de prediccions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35bc05d5-6ab3-4187-9da0-c44f8096a372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 309ms/step\n",
      "[[3.9316206e-03 1.0118769e-03 4.5908461e-03 1.6012216e-04 1.3765699e-01\n",
      "  6.2491935e-02 7.8777736e-01 3.7077724e-04 3.1905755e-04 1.6894789e-03]]\n",
      "nuemro prediccio:  6\n",
      "resposta:  5\n"
     ]
    }
   ],
   "source": [
    "prediccio = model.predict(np.array([x_test[8]]))\n",
    "print(prediccio)\n",
    "print('nuemro prediccio: ',np.argmax(prediccio))\n",
    "print('resposta: ',np.argmax(y_test[8]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
